{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "tgIPom80phqQ",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "yiiVWRdJDDil",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shasank55/yes-bank-close-price-pridiction/blob/main/Copy_of_Sample_ML_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** - Shasank chawla"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A well-known bank in the Indian financial industry is Yes Bank. The Rana Kapoor fraud case has been in the headlines since 2018 as a result of it. Due to this, it was interesting to observe how it affected the company's stock prices and whether Time series models or other prediction models could properly reflect for such circumstances. Since the bank's foundation, this dataset has included closing, starting, highest, and lowest stock values for each month. Predicting the stock's monthly closing price is the main goal.**\n",
        "\n",
        "We have 185 rows and 5 columns in our dataset. Here our dependent variable is Close and Independent variable is Open, High and Low.\n",
        "\n",
        "Date :- It denotes the month and year for a specific pricing.\n",
        "\n",
        "Open :- The price at which a stock started trading that month is referred to as the \"Open.\"\n",
        "\n",
        "High :- The highest price for that particular month.\n",
        "\n",
        "Low :- It describes the monthly minimum price.\n",
        "\n",
        "Close :- It refers to the final trading price for that month, which we have to predict using regression."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the Indian financial industry, Yes Bank is a well-known bank. Due to the Rana kapoor fraud case, it has been in the headlines since 2018. This made it interesting to investigate how it affected the company's stock prices and whether Time series models or other prediction models may be useful in such cases. Since the bank's inception, monthly stock prices have been collected in this dataset. Each month's closing, starting, highest, and lowest stock prices are included. The main goal is to forecast the stock's monthly closing price.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from datetime import timedelta\n",
        "from datetime import datetime   \n",
        "# This technique is used to divide the dataset into a training set and a test set when building the model.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Import libraries for Regressor\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import neighbors\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet \n",
        "\n",
        "# Import the matrix module to evaluate the model's performance.\n",
        "from sklearn.metrics import *\n",
        "import pandas.util.testing as tm\n",
        "\n",
        "# Import the variance inflation factor technique to reduce multicollinearity in independent variables.\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FV_QOF_1xB2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yb=pd.read_csv('/content/data_YesBank_StockPrices (4).csv')"
      ],
      "metadata": {
        "id": "DXBdD6_3zRQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "yb.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "yb.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "yb.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "yb.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "yb.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(yb.isnull(),cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset at hand comprises 185 observations and 5 attributes. The columns in the dataset are labeled as \"Date,\" \"Open,\" \"High,\" \"Low,\" and \"Close.\" There are no duplicate values present in the dataset and all the columns contain valid entries with no missing values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "yb.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "yb.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 185 rows and 5 columns in our dataset. Here our dependent variable is Close and Independent variable is Open, High and Low.\n",
        "\n",
        "Date :- It denotes the month and year for a specific pricing.\n",
        "\n",
        "Open :- The price at which a stock started trading that month is referred to as the \"Open.\"\n",
        "\n",
        "High :- The highest price for that particular month.\n",
        "\n",
        "Low :- It describes the monthly minimum price.\n",
        "\n",
        "Close :- It refers to the final trading price for that month, which we have to predict using regression."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "yb.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#In our data there is no null values and no duplicate value so our dataset analysis ready"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset, we have identified the number of rows and columns, and have also examined the unique values for each variable. We have then assessed the presence of duplicates and any missing values. The examination revealed that there are no duplicate values and all the columns contain valid entries, thus there are no missing values in the dataset. This dataset is now ready for analysis"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing 'Date' into datetime - 'YYYY-MM-DD' format\n",
        "yb['Date'] = yb['Date'].apply(lambda x: datetime.strptime(x,\"%b-%y\")) "
      ],
      "metadata": {
        "id": "q_Ns4Tw6qkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Yes Bank Closing Price Plotting\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.grid(True)\n",
        "plt.xlabel('Date', fontsize=10)\n",
        "plt.ylabel('Close Prices', fontsize=10)\n",
        "plt.plot(yb['Date'],yb['Close'])\n",
        "plt.title('Yes Bank closing price')\n",
        "sns.scatterplot(data=yb, x=\"Date\", y=\"Close\", s=100, color=\".2\")"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "vcHKa9hnuSrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use Scatter plots are used to visualize the relationship between two continuous variables and a scatter plot provides a more informative and interpretable representation of the data."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart is showing the closing price of the yes bank and showing trend of Yes Bank's closing price over time it can be determined by looking at the overall shape of the plot. For example, if the prices are generally increasing over time, it suggests an upward trend and vise versa."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the scatter plot of Yes Bank's closing price can potentially help create a positive business impact, a positive trend in the closing prices could indicate a positive impact on the business, while a negative trend could indicate a negative impact.As we can see in the chart a downward trend in the closing prices over a certain period of time may indicate a negative growth, but it could also be due to external factors such as changes in the market or economic conditions or some major issue in the company."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dependent variable of Close Price Stock**"
      ],
      "metadata": {
        "id": "wY-onnAAKEGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#Plot Open vs Close price using line graph\n",
        "# Display only last three year record\n",
        "\n",
        "yb[['Open','Close']].tail(36).plot(kind='line',figsize=(18,10))"
      ],
      "metadata": {
        "id": "9A75vOtFvIoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we chooose the line plot because we need to visualize the trend of the Open and Close columns of the data frame yb for the last 36 rows. The line plot is suitable for this task as it connects the data points with lines to show the change in the values over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart provides visual representation of the data in the Open and Close columns of the dataframe  for the last 36 observations. As we see in the chart that the stock from the uptrend to downtrend cover all this in just 36 months we need to know more about this to make some good decision for comapny."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes there is a sudden drop in the stock prices could be an insight that could lead to negative growth, we know because of various factors such as market conditions, company performance, and isssue with company we need to find and make some good decision to create positive impact for the comapny"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Dependent variable of Close Price Stock**"
      ],
      "metadata": {
        "id": "B35k_HAIa-vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Depndent Variable is \"Close\"\n",
        "# Normal Distribution\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(yb[\"Close\"], color=\"blue\")\n",
        "plt.title('Distribution')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use log transformation to make it normal distribution\n",
        "# Distribution plot of 'Closing' For applying log transformation\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(np.log10(yb[\"Close\"]), color=\"blue\")\n",
        "plt.title('Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lE9mALjraZOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we choose this specefic graph because we have to create a distribution plot of the \"Close\" variable to visualize the shape of the distribution and assess whether it is approximately normally distributed."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart displays the distribution of the \"Close\" variable. The first chart shows it's approximately normal, the second shows it's a normal bell-shaped curve. transforming the data to make it more normal improves performance of statistical methods and ML algorithms.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution plots of \"Close\" variable help assess its normality, a key assumption for statistical methods and ML algorithms. If it's not normal, transforming it to make it more normal can improve performance and create positive business impact. The \"Close\" variable is positively skewed but log transforming it makes it closer to a normal distribution.\n",
        "There is no specific insight from the data that leads to negative growth."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Independent Variable Open , High and Low price of stock**"
      ],
      "metadata": {
        "id": "35f8EVVAbBoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Distribution plot of 'Low price' For applying log transformation\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(np.log10(yb[\"Low\"]), color=\"Black\")\n",
        "plt.title('Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "03BrvCUvMOL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line plots are used to visualize data over a continuous interval or time period"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution plot of the log transformed \"Low\" variable shows the distribution of the data after being transformed by the log function. The plot may provide insight into whether the transformed \"Low\" variable is approximately normally distributed, which is a key assumption for many statistical methods and machine learning algorithms. "
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this plot, the log transformed \"Low\" variable appears to be closer to a normal distribution, which can improve the performance of statistical methods and machine learning algorithms used for analysis, leading to a positive business impact.\n",
        "\n",
        "There is no specific insight from the data that leads to negative growth.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Distribution plot of 'Open' For applying log transformation\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(np.log10(yb[\"Open\"]), color=\"Red\")\n",
        "plt.title('Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use the line plot because we can visualize the stangant stock price in a good way"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution plot of the log transformed \"Open\" variable shows the distribution of the transformed variable. The plot can provide insight into whether the transformed variable is approximately normally distributed, which is important for many statistical methods and machine learning algorithms."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming the \"Open\" variable to make it more normally distributed can improve performance of statistical methods and algorithms, after this you acbn pridict the price leading to positive business impact. No negative impact is indicated.growth."
      ],
      "metadata": {
        "id": "hIp7cBqQZN0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Distribution plot of 'High' For applying log transformation\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(np.log10(yb[\"High\"]), color=\"Green\")\n",
        "plt.title('Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A distribution plot is a useful tool for understanding the spread of the data and identifying any potential outliers or skewness in the data. In this case, the distribution plot of the closing price of the stock can provide valuable insight into the stock's performance, including the range and frequency of stock prices."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart is a distribution plot of the \"High\" column in the data after applying log transformation. The plot displays the distribution of the log transformed \"High\" column values. The insights gained from the chart help in understanding the distribution of the log transformed \"High\" values. However, it's difficult to determine the business impact from the chart without additional context and information."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "these distribution plots help to visualize the distribution of the target variable, in this case, the \"High\" prices of the stock. The log transformation helps to bring the distribution closer to a normal distribution which can be helpful for certain statistical analysis and modeling technique. the insights from these plots will lead to a positive or negative business impact."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Plot the histogram of the \"Close\" column\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "ax = fig.gca()\n",
        "feature = yb['Close']\n",
        "feature.hist(bins=50, ax = ax)\n",
        "ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)    \n",
        "ax.set_title('Close')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use the bar plot because it is easy to show the numerical numbers"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram of the \"Close\" column displays the distribution of the closing prices. The chart shows the frequency of occurrence of different closing prices. The mean and median values of the closing prices are also shown on the chart\n",
        "\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram of \"Close\" prices shows distribution and central tendency (mean, median) but does not indicate positive impact or negative growth. Further analysis is needed to determine business impact."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Plot the histogram of the \"Open\" column\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "ax = fig.gca()\n",
        "feature = yb['Open']\n",
        "feature.hist(bins=50, ax = ax)\n",
        "ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)    \n",
        "ax.set_title('Open')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked a histogram to display the distribution of the \"Open\" column, showing the frequency of each value range in the data set, and to highlight the mean and median values as reference points."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows the distribution of the \"Open\" column of the data with a histogram, with mean and median displayed. The shape of the histogram can give insight into the distribution of the data and its skewness."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram of \"Open\" values can provide positive impact by showing average and typical values, useful for setting targets/budgets. However, it does not show negative growth insights."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Plot the histogram of the \"Low\" column\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "ax = fig.gca()\n",
        "feature = yb['Low']\n",
        "feature.hist(bins=50, ax = ax)\n",
        "ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)    \n",
        "ax.set_title('Low')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked a histogram to display the distribution of the \"Low\" column, showing the frequency of each value range in the data set, and to highlight the mean and median values as reference points."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram displays the distribution of the \"Low\" column in the data set, with the frequency of each value range shown. The mean and median values are indicated as reference points, providing insight into the center and typical values of the data set. The distribution appears to be slightly positively skewed, with more values on the higher end."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram of \"Low\" values provides information on their distribution, which can guide pricing decisions. If values are mostly low, company may lower prices, but if values are mostly high, they may increase prices. However, it does not show negative growth insights."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Plot the histogram of the \"High\" column\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "ax = fig.gca()\n",
        "feature = yb['High']\n",
        "feature.hist(bins=50, ax = ax)\n",
        "ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)    \n",
        "ax.set_title('High')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked a histogram to display the distribution of the \"high\" column, showing the frequency of each value range in the data set, and to highlight the mean and median values as reference points."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram of the \"High\" column can inform business decisions by showing the distribution of \"High\" values. If most values are high, the company may consider increasing interests to maximize profits, or lower prices if values are mostly low. But negative impact triggers are not shown."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Now, find out the relation between the Dependent Variable and Independent Variable**"
      ],
      "metadata": {
        "id": "nSxFVYjyb14a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Scatter Plot Close or Low\n",
        "plt.scatter(yb['Close'],yb['Low'], alpha=0.2)\n",
        "plt.title('Scatter Plot of Low or Close')\n",
        "sns.regplot(data= yb, x ='Low', y ='Close', color=\"DarkRed\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked a scatter plot to visualize the relationship between the \"Close\" and \"Low\" columns, with a regression line added to see if there is any correlation between the two variables."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows the relationship between the \"Low\" and \"Close\" values, with a regression line to indicate the overall trend. The insights found show the correlation between the \"Low\" and \"Close\" values, indicating that they are likely to be positively related."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot of \"Close\" and \"Low\" can highlight growth opportunities if a positive correlation exists, but doesn't show any negative impacts."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# By using scatter plot, we can find out the relation b/w the Dependent Variable and Independent Variable\n",
        "# Scatter Plot of 'Close or Open'\n",
        "plt.scatter(yb['Close'],yb['Open'], alpha=0.2)\n",
        "plt.title('Scatter Plot of Open or Close')\n",
        "sns.regplot( data= yb, x ='Open', y ='Close', color=\"Darkorange\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "10kl8SMXtfCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked a scatter plot to visualize the relationship between the \"Close\" and \"open\" columns, with a regression line added to see if there is any correlation between the two variables."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows the relationship between the \"open\" and \"Close\" values, with a regression line to indicate the overall trend. The insights found show the correlation between the \"open\" and \"Close\" values, indicating that they are likely to be positively related."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot provides a visual representation of the relationship between the dependent variable (Close) and the independent variable (Open). However, the impact of the insights gained from the plot on business growth cannot be determined solely based on the plot itself. The positive or negative impact would depend on various factors such as market conditions, company performance, and other external factors. The regression line on the scatter plot helps to identify the general trend, but further analysis is required to understand the impact on business growth. Without additional information, it is not possible to determine whether the insights lead to positive or negativegrowth."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Scatter Plot Close or High\n",
        "plt.scatter(yb['Close'],yb['High'], alpha=0.2)\n",
        "plt.title('Scatter Plot of High or Close')\n",
        "sns.regplot( data= yb, x ='High', y ='Close', color=\"DarkBlue\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot and regression plot were chosen to visualize the relationship between the closing and high prices of a stock or security. The scatter plot provides a general overview of the distribution of the data points while the regression line provides an estimate of the relationship between the variables."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot and regression plot were chosen to visualize the relationship between the closing and high prices of a stock or security. The scatter plot provides a general overview of the distribution of the data points while the regression line provides an estimate of the relationship between the variables. The alpha parameter in the scatter plot sets the transparency level of the data points, allowing for easier visualization of the concentration of data points."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot and regression line help in analyzing the relationship between the High and Close prices of a stock. However, it is difficult to determine if these insights will lead to a positive business impact as it depends on various other factors such as the overall market conditions, industry trends, and the company's financial performance. The insights may lead to negative growth if the regression line shows a negative relationship between the High and Close prices, indicating a decreasing trend in the stock's value."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "correlation = yb.corr()\n",
        "sns.heatmap(abs(correlation), annot = True, cmap='coolwarm')\n",
        "     "
      ],
      "metadata": {
        "id": "kU5frNteOpa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatmap is a useful tool for visualizing the correlation between variables in a dataset. The chart uses color to represent the magnitude of the correlation between variables, with warm colors (red and yellow) representing positive correlation and cool colors (green and blue) representing negative correlation."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation heatmap shows the strength of the relationship between different variables in the data set. It indicates which variables are positively or negatively correlated and to what extent. The chart highlights the correlations between variables in the data set and provides insights into which variables are affecting each other. the Open and Close prices are highly correlated, it suggests that the opening price of the stock is a good predictor of its closing price. This information can be used by traders and investors to make informed decisions about when to buy or sell a stock.the high correlation between the High and Low prices suggests that the daily fluctuation of a stock price is consistent. This information could be used to estimate the volatility of a stock and to make predictions about its future price movements.\n",
        "\n"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Multicollinearity**"
      ],
      "metadata": {
        "id": "TDtECimLzcXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the variation inflation factor (VIF), To determine the correlation between independent variables."
      ],
      "metadata": {
        "id": "xltC5Y76zyTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Calc_vif(X):\n",
        "# Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"Variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "QixjNdvGzap-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Calc_vif(yb[[i for i in yb.describe().columns if i not in [\"Date\", \"Close\"]]])"
      ],
      "metadata": {
        "id": "PYtuYhAN0Gry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though we have strong VIF ratings, we won't do feature engineering because each feature is critical for this specific use case. Most indicators in the real world consider each of these characteristics to predict future values.\n",
        "\n",
        "Due to the fact that each column is equally crucial for prediction, we are not deleting any columns.\n",
        "\n",
        "Column removal resulted in the loss of important data (features) that are necessary for the model to make correct predictions. It produces a poor model.\n",
        "\n",
        "Therefore, we are not removing any features from the dataset while we attempt to predict the outcome, assess the model's performance with respect to multicollinearity, and make adjustments as necessary."
      ],
      "metadata": {
        "id": "cDyvFGWF0VgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(yb,kind=\"scatter\")"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the pairplot chart because it is a useful tool for exploring the relationships between variables in a dataset. The chart creates scatter plots between every pair of variables in the dataset, providing a comprehensive view of the relationships between the variables. The scatter plots are useful in determining if there is a linear relationship between two variables, as well as the strength and direction of the relationship."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pairplot is a powerful tool for exploring the relationships between variables in a dataset. The chart creates a scatter plot matrix, which plots each variable against every other variable in the dataset. The scatter plots show the relationships between each pair of variables, and can help in identifying trends and patterns in the data. The scatter plots can also help in detecting outliers, which can have a significant impact on the accuracy of the model predictions. By visually inspecting the relationships between variables, we can gain insights into the data, such as the distribution of the variables, the presence of linear or non-linear relationships, and the degree of association between variables. These insights can be useful in making informed business decisions and in developing effective data-driven strategies.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot and regression line, the following three hypothetical statements can be made:\n",
        "There is a positive linear relationship between the Low and Close prices.\n",
        "The Low prices tend to be lower than the Close prices.\n",
        "The Close prices and Low prices are not significantly different.\n",
        "\n",
        "For each statement, we can set up the null and alternative hypotheses:\n",
        "\n",
        "Null Hypothesis (H0): There is no relationship between the Low and Close prices.\n",
        "\n",
        "\n",
        "Alternative Hypothesis (Ha): There is a positive linear relationship between the Low and Close prices\n",
        "\n",
        "\n",
        "Null Hypothesis (H0): The Low prices are equal to the Close prices.\n",
        "\n",
        "\n",
        "\n",
        "Alternative Hypothesis (Ha): The Low prices are lower than the Close prices.\n",
        "\n",
        "\n",
        "\n",
        "Null Hypothesis (H0): The Close prices and Low prices are significantly different.\n",
        "\n",
        "\n",
        "\n",
        "Alternative Hypothesis (Ha): The Close prices and Low prices are not significantly different."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Fit a linear regression model\n",
        "x = yb['Low']\n",
        "y = yb['Close']\n",
        "x = sm.add_constant(x)\n",
        "model = sm.OLS(y, x).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test performed to obtain the p-value is Ordinary Least Squares (OLS) regression, which is a type of linear regression analysis. In OLS regression The p-value for the slope of the regression line represents the probability that the observed relationship between the variables is due to chance."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "because OLS regression is used to analyze relationship between two continuous variables (Low price and Close price). It determines strength, direction, and significance of relationship with a p-value. Assumes linear relationship, as shown in scatter plot and regression line."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the scatter plot, one could make the following three hypothetical statements:\n",
        "\n",
        "There is a positive linear relationship between the opening price and the closing price.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Null Hypothesis (H0): There is no relationship between the opening price and the closing price.\n",
        "\n",
        "\n",
        "\n",
        "Alternate Hypothesis (Ha): There is a positive linear relationship between the opening price and the closing price.\n",
        "\n",
        "The mean of the opening price is equal to the mean of the closing price.\n",
        "\n",
        "\n",
        "\n",
        "Null Hypothesis (H0): The mean of the opening price is not equal to the mean of the closing price.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Alternate Hypothesis (Ha): The mean of the opening price is equal to the mean of the closing price.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The standard deviation of the opening price is equal to the standard deviation of the closing price.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Null Hypothesis (H0): The standard deviation of the opening price is not equal to the standard deviation of the closing price.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Alternate Hypothesis (Ha): The standard deviation of the opening price is equal to the standard deviation of the closing price.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import statsmodels.api as sm\n",
        "\n",
        "yb = yb.dropna()\n",
        "X = yb['Open']\n",
        "y = yb['Close']\n",
        "X = sm.add_constant(X)\n",
        "model = sm.OLS(y, X).fit()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code uses OLS regression to analyze the relationship between the opening and closing price of a stock. The P-Value in the OLS model's summary determines if the opening price significantly affects the closing price. If the P-Value is less than 0.05, it suggests that the opening price has a real effect on the closing price. If the P-Value is greater than 0.05, it suggests that the opening price has no effect."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The OLS regression was used to model the relationship between the closing price and opening price. OLS is for linear relationships with a continuous dependent variable and finds a linear equation by minimizing the difference between actual and predicted values. The coefficients represent the change in the dependent variable per unit change in the independent variable. The OLS regression is performed using the OLS function and results are summarized using summary from the statsmodels library."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scatter plot has the following three hypothetical statements can be made about the relationship between the Close and High prices in the dataset:\n",
        "\n",
        "There is a positive relationship between the Close and High prices.\n",
        "The Close price is equal to the High price.\n",
        "The Close price is a linear function of the High price.\n",
        "\n",
        "\n",
        "For each of these statements, we need to perform hypothesis testing to determine if the statement is supported by the data or not.\n",
        "\n",
        "\n",
        "Positive relationship between Close and High prices:\n",
        "\n",
        "\n",
        "Null hypothesis (H0): There is no relationship between the Close and High prices.\n",
        "\n",
        "\n",
        "Alternative hypothesis (Ha): There is a positive relationship between the Close and High prices.\n",
        "\n",
        "\n",
        "\n",
        "Close price is equal to High price:\n",
        "\n",
        "\n",
        "Null hypothesis (H0): The Close price is not equal to the High price.\n",
        "\n",
        "\n",
        "Alternative hypothesis (Ha): The Close price is equal to the High price.\n",
        "\n",
        "\n",
        "\n",
        "Close price is a linear function of the High price:\n",
        "\n",
        "\n",
        "Null hypothesis (H0): The Close price is not a linear function of the High price.\n",
        "\n",
        "\n",
        "Alternative hypothesis (Ha): The Close price is a linear function of the High price.\n",
        "\n",
        "\n",
        "\n",
        "For each of the above hypotheses, we would need to perform a statistical test and use the results to accept or reject the null hypothesis and arrive at a conclusion."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Calculate Pearson's correlation coefficient\n",
        "r, p_value = stats.pearsonr(yb['Close'], yb['High'])\n",
        "\n",
        "# Interpret the results\n",
        "if p_value < 0.05:\n",
        "    print(\"The p-value of\", p_value, \"indicates that there is a significant positive relationship between Close and High prices.\")\n",
        "else:\n",
        "    print(\"The p-value of\", p_value, \"indicates that there is no significant relationship between Close and High prices.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test performed in this code to obtain the p-value is Pearson's correlation coefficient. Pearson's correlation coefficient is a measure of the linear association between two continuous variables and ranges from -1 to 1, where -1 indicates a perfect negative linear relationship.In this case, the p-value is used to determine if there is a significant positive relationship between the Close and High prices."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pearson's correlation coefficient test was chosen to measure the linear association between Close and High prices and determine if there is a significant positive relationship. The test provides a measure of strength and direction and the p-value helps test the hypothesis."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "sns.heatmap(yb.isnull(),cbar=False)\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no missing value in the dataset so we don't need to do any techniques"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.boxplot(y=yb['Open'])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(y=yb['Close'],color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.boxplot(y=yb['High'],color='green')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(y=yb['Low'],color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kqtalNooMm56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One common outlier treatment technique used with box plots is to identify and remove outliers. This is done by calculating the lower and upper bounds of the plot and any data points that fall outside these bounds are considered outliers. The reason for removing outliers is that they can have a significant impact on the analysis and skew the results, leading to inaccurate conclusions. By removing outliers, we can get a more accurate representation of the data and avoid making incorrect assumptions."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**We don't use  functions from 3( categorical encoding ) to 10 (Text Vectorization) in our regression as our data is in numerical format**"
      ],
      "metadata": {
        "id": "XueQ2ivpsaYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Creating a new feature based on average of other features in the dataset\n",
        "yb['OHL'] = yb[['Open', 'High', 'Low']].mean(axis=1).round(2)\n",
        "yb.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression also assumes a linear relationship between the target variables and independent variables, let's check if such relationship exists through a scatter plot"
      ],
      "metadata": {
        "id": "56ayS6NRilpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot to see the relationship between dependent & independent variables\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "ax = fig.gca()\n",
        "plt.scatter(yb['OHL'], yb['Close'])\n",
        "plt.xlabel('OHL')\n",
        "plt.ylabel('Close')\n",
        "ax.set_title('OHL vs Close')\n",
        "z = np.polyfit(yb['OHL'], yb['Close'], 1)\n",
        "y_hat = np.poly1d(z)(yb['OHL'])\n",
        "plt.plot(yb['OHL'], y_hat, \"r--\", lw=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "48uPx4uFinhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Choose features based on correlation with the target\n",
        "corr = yb.corr()['Close'].sort_values()\n",
        "corr"
      ],
      "metadata": {
        "id": "KhZKY9QVkG05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(yb.corr())\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hqMw0YJVkJZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep features that have a correlation of 0.5 or higher with the target\n",
        "features = corr[abs(corr) >= 0.5].index"
      ],
      "metadata": {
        "id": "uEVIE-AHjmIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop features that are highly correlated with each other\n",
        "features = features.drop(['Close'])\n",
        "features\n"
      ],
      "metadata": {
        "id": "L9Gt6NEpjpBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataset with only the selected features\n",
        "yb_selected = yb[features]\n",
        "yb_selected"
      ],
      "metadata": {
        "id": "RZpLs_Zcj2iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the correlation between each feature and the target (Close) is calculated using the corr method. Features with a correlation of 0.5 or higher with the target are selected, and features that are highly correlated with each other are dropped. The final result is a new dataset with only the selected features. By choosing only the most relevant features, overfitting can be prevented and the model can be improved."
      ],
      "metadata": {
        "id": "lMVFoJdFjaHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use Pearson's correlation coefficient to select features based on their correlation with the target 'Close' price. Features with a correlation >= 0.5 are kept,This method is used because it provides a way to quantify the strength of the relationship between each feature and the target, and can be used to identify the most relevant features for modeling. this also drop the features which is highly correlated features are dropped to avoid over fitting."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are many more features but we use Pearson's correlation coefficient to identify the features with a correlation of 0.5 or higher with the target 'Close' price and considers them as important. This method assumes a strong linear relationship between the features and the target results in good predictive power. "
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the data\n",
        "from scipy.stats import zscore\n",
        "x = X.apply(zscore)\n",
        "y = np.log10(y)"
      ],
      "metadata": {
        "id": "rz6yDz6EU5T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the data\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "73MCZKx3de5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the datasets\n",
        "X = yb.drop(columns=['Close','Date'])\n",
        "y = yb['Close']"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the data\n",
        "from scipy.stats import zscore\n",
        "x = X.apply(zscore)\n",
        "y = np.log10(y)"
      ],
      "metadata": {
        "id": "WjAypnVad1G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our data into train and test datasets\n",
        "# Train and Test Set data splitted into 70-30\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,random_state= 1)"
      ],
      "metadata": {
        "id": "_BLGLOVCUVlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the Training dataset\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "AV26tISSUbuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the Test dataset\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "BwrA18ZKUkBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train data \n",
        "y_train.head()"
      ],
      "metadata": {
        "id": "aF2DDXG7UpXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are dividing the train and test data into 70,30 ratio.The 70% of the data is used for training the model, and the remaining 30% is used for evaluating the model's performance. This ratio provides a good balance between having enough data to train the model and having enough data to test its accuracy. By testing the model on unseen data, we can get a good idea of how well the model will perform in real-world scenarios."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "lr= LinearRegression()\n",
        "\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "lr.fit(x_train, y_train)\n",
        "round(lr.score(x_train,y_train), 4)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(lr.score(x_test, y_test), 4)"
      ],
      "metadata": {
        "id": "rZ_dJGlRZOeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "\n",
        "Prediction=lr.predict(x_test)\n",
        "Prediction"
      ],
      "metadata": {
        "id": "8arzLrHSYd1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "6o3ZbG7NepKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the DataFrames of test & train Dataset\n",
        "train_Dataframe = pd.DataFrame(x_train,y_train)\n",
        "test_Dataframe = pd.DataFrame(y_test)\n",
        "test_Dataframe.rename(columns= {'Close' :'Actual Closing Price'}, inplace =True)"
      ],
      "metadata": {
        "id": "kbz1w2yEfHGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_Dataframe['Predicted Closing Price']= Prediction\n",
        "test_Dataframe.head()"
      ],
      "metadata": {
        "id": "GLc2A6h8fKbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Prediction[0:5]"
      ],
      "metadata": {
        "id": "rNIVvI7UfW64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Performence of Linear Regression Model\n",
        "print('Performance of Linear Regression Model')\n",
        "print(\"MSE :\",round(mean_squared_error(y_test, Prediction),4))\n",
        "print(\"RMSE :\",round(math.sqrt(mean_squared_error(y_test, Prediction)),4))\n",
        "print(\"MAE :\",round(mean_absolute_error(y_test, Prediction),4))\n",
        "print(\"MAPE :\",round(mean_absolute_percentage_error(y_test, Prediction),4))\n",
        "print(\"R2 :\",round(r2_score(y_test, Prediction),4))"
      ],
      "metadata": {
        "id": "TzGGZ4Brfer5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Sctter Plot of Actual vs Predicted Values\n",
        "plt.scatter(y_test,Prediction)\n",
        "plt.xlabel('Actual test value')\n",
        "plt.ylabel('Predicted test value')\n",
        "\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual Price vs Prediction price for Linear Regression plot:\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(10**(Prediction))             \n",
        "plt.plot(10**(np.array(y_test)))           \n",
        "plt.xlabel(\"No. of test data\",fontsize= 12)\n",
        "plt.ylabel(\"Price\",fontsize= 12)\n",
        "plt.suptitle(\"Actual Stock Close Price VS Predicted Stock Close Price\",fontsize=14)\n",
        "plt.legend([\"Predicted\",\"Actual\"],fontsize= 12)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bTqoTbfifsfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JidcmD5xl1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid = {'normalize': [True, False],\n",
        "              'fit_intercept': [True, False]}\n",
        "\n",
        "# Define the grid search\n",
        "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we use the GridSearchCV function from scikit-learn's model_selection module to perform a grid search over the hyperparameters normalize and fit_intercept of a linear regression model. The grid search uses 5-fold cross-validation and the neg_mean_squared_error scoring metric to evaluate the performance of the model on each combination of hyperparameters. The fit method is used to fit the grid search to the data, and the best_params_ attribute is used to print the hyperparameters that gave the best performance."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a regression model, hyperparameter tuning is used to find the best combination of hyperparameters that lead to the highest model performance. In this case, the code is using GridSearchCV to perform hyperparameter tuning on the regression model, with two hyperparameters fit_intercept and normalize. The best parameters found are fit_intercept=True and normalize=True, meaning the model should include an intercept and normalize the features before regression."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Implementing Lasso Regression**"
      ],
      "metadata": {
        "id": "Cb2p0ODkhfDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso(least absolute shrinkage and selection operator) regression is another technique of Parameter estimation regression method. This method is usually used in machine learning for the selection of the subset of variables. It provides greater prediction accuracy as compared to other regression models. Lasso Regularization enhances the accessibility of models."
      ],
      "metadata": {
        "id": "kpA_B-fYhoU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "lasso = Lasso(alpha=0.001, max_iter=5000)\n",
        "lasso.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Accuracy Score of Lasso Rigression Model\n",
        "lasso_score = lasso.score(x_train,y_train)\n",
        "lasso_score"
      ],
      "metadata": {
        "id": "yB6YCmZ4h0YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso Regression Predicted train Data Value:\n",
        "pred_Lasso = lasso.predict(x_test)\n",
        "pred_Lasso"
      ],
      "metadata": {
        "id": "TpR7q22sh5UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tesingt performance of Lasso Regression Model\n",
        "print('Performance of Lasso Regression Model')\n",
        "print(\"MSE :\",round(mean_squared_error(y_test, pred_Lasso), 4))\n",
        "print(\"RMSE :\",round(math.sqrt(mean_squared_error(y_test, pred_Lasso)),4))\n",
        "print(\"MAE :\",round(mean_absolute_error(y_test, pred_Lasso),4))\n",
        "print(\"MAPE :\",round(mean_absolute_percentage_error(y_test, pred_Lasso),4))\n",
        "print(\"R2 :\",round(r2_score(y_test, pred_Lasso), 4))"
      ],
      "metadata": {
        "id": "qmY5nl1DiXBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a column to the test dataset will allow to compare the Actual and Predicted values.\n",
        "\n",
        "test_Dataframe['Lasso Predicted Closing Price'] = pred_Lasso\n",
        "lasso_dataframe = test_Dataframe.loc[:,['Actual Closing Price','Lasso Predicted Closing Price']]\n",
        "lasso_dataframe.head(6)"
      ],
      "metadata": {
        "id": "thTfx8E4ig8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "xwxw4p7ni2uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Scatter Plot Actual Value vs Predicted Value\n",
        "plt.scatter((y_test), (pred_Lasso))\n",
        "plt.xlabel('Actual Value')\n",
        "plt.ylabel('Predicted Value')"
      ],
      "metadata": {
        "id": "aAtse_xyi5CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual Price vs Prediction price for Linear Regression plot:\n",
        "\n",
        "plt.figure(figsize=(13,6.5))\n",
        "plt.plot(10**(pred_Lasso))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.xlabel(\"No. of test data\",fontsize= 12)\n",
        "plt.ylabel(\"Price\",fontsize= 12)\n",
        "plt.suptitle(\"Actual closing price vs Lasso Predicted Price\",fontsize=14)\n",
        "plt.legend([\"Lasso Predicted\",\"Actual\"],fontsize= 12)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y-u79h0yn28c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid = {'normalize': [True, False],\n",
        "              'fit_intercept': [True, False]}\n",
        "\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_search.fit(X, y)\n",
        "# Predict on the model\n",
        "print(\"Best parameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we use the GridSearchCV function from scikit-learn's model_selection module to perform a grid search over the hyperparameters normalize and fit_intercept of a linear regression model. The grid search uses 5-fold cross-validation and the neg_mean_squared_error scoring metric to evaluate the performance of the model on each combination of hyperparameters. The fit method is used to fit the grid search to the data, and the best_params_ attribute is used to print the hyperparameters that gave the best performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a regression model, hyperparameter tuning is used to find the best combination of hyperparameters that lead to the highest model performance. In this case, the code is using GridSearchCV to perform hyperparameter tuning on the regression model, with two hyperparameters fit_intercept and normalize. The best parameters found are fit_intercept=True and normalize=True, meaning the model should include an intercept and normalize the features before regression."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics used in the code snippet provide insights into the performance of the Lasso Regression Model. These metrics help to determine the model's accuracy and its ability to make predictions that align with the actual values.\n",
        "\n",
        "1.Mean Squared Error (MSE): MSE measures the average of the squares of the differences between the actual and predicted values. A lower MSE indicates a better fit between the actual and predicted values. A low MSE in this case would indicate a positive business impact as it means the model is making accurate predictions.\n",
        "\n",
        "2.Root Mean Squared Error (RMSE): RMSE is the square root of MSE. It measures the average difference between the actual and predicted values in the same unit as the response variable. A low RMSE value indicates a better fit between the actual and predicted values.\n",
        "\n",
        "3.Mean Absolute Error (MAE): MAE measures the average of the absolute differences between the actual and predicted values. A lower MAE value indicates a better fit between the actual and predicted values.\n",
        "\n",
        "4.Mean Absolute Percentage Error (MAPE): MAPE measures the average percentage difference between the actual and predicted values. A lower MAPE value indicates a better fit between the actual and predicted values.\n",
        "\n",
        "5.R-squared (R2): R2 measures the proportion of variation in the response variable that is explained by the predictor variables. A higher R2 value indicates a better fit between the actual and predicted values.\n",
        "\n",
        "In conclusion, a high R2 value and low values for MSE, RMSE, MAE, and MAPE would indicate a positive business impact, as it means the model is making accurate predictions."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Implementation of Ridge Regression**"
      ],
      "metadata": {
        "id": "e66PVnoAon2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge regression is a model-tuning technique that is used to analyse any multicollinear data. L2 regularisation is done using this technique. The projected values vary significantly from the actual values when the problem of multicollinearity is present, least-squares are unbiased, and variances are large."
      ],
      "metadata": {
        "id": "ybmaHDD1owDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "#Importing Libraries\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Fit the Algorithm\n",
        "ridge = Ridge(alpha= 0.1)\n",
        "ridge.fit(x_train,y_train)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy \n",
        "round(ridge.score(x_train, y_train), 4)"
      ],
      "metadata": {
        "id": "PYnQIEUhqx6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "ridge_y_pred = ridge.predict(x_test)\n",
        "ridge_y_pred"
      ],
      "metadata": {
        "id": "NlylzSFSqJ5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "gSjasg5Wq1nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tesingt performance of Ridge Regression Model\n",
        "print('Performance of Ridge Regression Model')\n",
        "print(\"MSE :\",round(mean_squared_error(y_test, ridge_y_pred), 4))\n",
        "print(\"RMSE :\",round(math.sqrt(mean_squared_error(y_test, ridge_y_pred)),4))\n",
        "print(\"MAE :\",round(mean_absolute_error(y_test, ridge_y_pred),4))\n",
        "print(\"MAPE :\",round(mean_absolute_percentage_error(y_test, ridge_y_pred),4))\n",
        "print(\"R2 :\",round(r2_score(y_test, ridge_y_pred), 4))"
      ],
      "metadata": {
        "id": "5_tYAd7urA4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "plt.scatter((y_test),(ridge_y_pred))\n",
        "plt.xlabel('Real Value')\n",
        "plt.ylabel('Predicted Value')\n",
        "     "
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Graph\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(10**(ridge_y_pred))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Real Vs Predicted Value', fontsize= 14)\n",
        "plt.xlabel('No. of Test Data', fontsize = 12)\n",
        "plt.ylabel('Ridge closing Price', fontsize= 12)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "zgcHjcjprK1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "\n",
        "param_grid = {'normalize': [True, False],\n",
        "              'fit_intercept': [True, False]}\n",
        "\n",
        "# Define the grid search\n",
        "grid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we use the GridSearchCV function from scikit-learn's model_selection module to perform a grid search over the hyperparameters normalize and fit_intercept of a linear regression model. The grid search uses 5-fold cross-validation and the neg_mean_squared_error scoring metric to evaluate the performance of the model on each combination of hyperparameters. The fit method is used to fit the grid search to the data, and the best_params_ attribute is used to print the hyperparameters that gave the best performance."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a regression model, hyperparameter tuning is used to find the best combination of hyperparameters that lead to the highest model performance. In this case, the code is using GridSearchCV to perform hyperparameter tuning on the regression model, with two hyperparameters fit_intercept and normalize. The best parameters found are fit_intercept=True and normalize=True, meaning the model should include an intercept and normalize the features before regression."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low MSE, RMSE, and MAE and high R2 score indicate a well-performing Ridge Regression Model with accurate predictions. MAPE can also be used to measure error in percentage terms. The choice of evaluation metrics should align with business objectives and data characteristics. In this case, the model has a low MSE, RMSE, MAE, and high R2 score, with a MAPE of 0.0973 suggesting an average error of 9.73%."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Ridge Regression Model we choose is likely the best choice for the final prediction model based on its low MSE, RMSE, and MAE values, and high R2 score. However, additional factors such as interpretability, computational efficiency, and handling of large datasets should also be considered, and further analysis such as cross-validation may be beneficial.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Ridge Regression model was used in this case, it's a linear regression model that uses L2 regularization to avoid overfitting. Feature importances can be determined using various methods such as the coef_ attribute or permutation feature importances. Visualization techniques, such as partial dependence plots, can also be used to understand the relationship between features and target variables. However, feature importances should be interpreted in the context of the specific data and problem."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "\n",
        "1.The trend of Yes Bank's stock price showed an increase until 2018 and then a decrease in Close, Open, High, and Low prices.\n",
        "\n",
        "2.The open vs. close price graph indicates a significant drop in Yes Bank's stock starting from 2018.\n",
        "\n",
        "3.The data showed that duplicate and null values are absent, however, the Date feature was in object data type and was transformed to YYYY-MM-DD format.\n",
        "\n",
        "4.The relationship between the dependent and independent values was found to be linear.\n",
        "\n",
        "5.The data showed a high level of multicollinearity.\n",
        "\n",
        "Visual analysis of the closing price of the stock revealed a sudden decrease starting in 2018, which is believed to have been caused by the Rana Kapoor case fraud.\n",
        "\n",
        "Five regression models were created for the data: Linear Regression, Lasso Regression, and Ridge Regression. These models showed that the High, Low, and Open values are directly related to the Closing price of the stock."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}